{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ao399CMu9888"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7uNWd2rs2fZW"
      },
      "outputs": [],
      "source": [
        "# Do we have access to a GPU?\n",
        "device_list = tf.config.list_physical_devices()\n",
        "if \"GPU\" in [device.device_type for device in device_list]:\n",
        "  print(f\"[INFO] TensorFlow has GPU available to use. Woohoo!! Computing will be sped up!\")\n",
        "  print(f\"[INFO] Accessible devices:\\n{device_list}\")\n",
        "else:\n",
        "  print(f\"[INFO] TensorFlow does not have GPU available to use. Models may take a while to train.\")\n",
        "  print(f\"[INFO] Accessible devices:\\n{device_list}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDvfRmUqx0C5"
      },
      "source": [
        "## 2. Getting Data\n",
        "\n",
        "* The [original project website](http://vision.stanford.edu/aditya86/ImageNetDogs/) via link download.\n",
        "* Inside [TensorFlow datasets under `stanford_dogs`](https://www.tensorflow.org/datasets/catalog/stanford_dogs).\n",
        "* On [Kaggle as a downloadable dataset](https://www.kaggle.com/datasets/jessicali9530/stanford-dogs-dataset).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "b_md5OPJ98nb"
      },
      "outputs": [],
      "source": [
        "# Download the dataset into train and test split using TensorFlow Datasets\n",
        "# import tensorflow_datasets as tfds\n",
        "# ds_train, ds_test = tfds.load('stanford_dogs', split=['train', 'test'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tHF13s8UbzK"
      },
      "source": [
        "\n",
        "\n",
        "1. [Images](http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar) (757MB) - `images.tar`\n",
        "3. [Annotations](http://vision.stanford.edu/aditya86/ImageNetDogs/annotation.tar) (21MB) - `annotation.tar`\n",
        "3. [Lists](http://vision.stanford.edu/aditya86/ImageNetDogs/lists.tar) with train/test splits (0.5MB) - `lists.tar`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHOkXNmeDgZq"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. Mount Google Drive (this will bring up a pop-up to sign-in/authenticate)\n",
        "# Note: This step is specifically for Google Colab, if you're working locally, you may need a different setup\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "# 2. Setup constants\n",
        "# Note: For constants like this, you'll often see them created as variables with all capitals\n",
        "TARGET_DRIVE_PATH = Path(\"drive/MyDrive/tensorflow/dog_vision_data\")\n",
        "TARGET_FILES = [\"images.tar\", \"annotation.tar\", \"lists.tar\"]\n",
        "TARGET_URL = \"http://vision.stanford.edu/aditya86/ImageNetDogs\"\n",
        "\n",
        "# 3. Setup local path\n",
        "local_dir = Path(\"dog_vision_data\")\n",
        "\n",
        "# 4. Check if the target files exist in Google Drive, if so, copy them to Google Colab\n",
        "if all((TARGET_DRIVE_PATH / file).is_file() for file in TARGET_FILES):\n",
        "  print(f\"[INFO] Copying Dog Vision files from Google Drive to local directory...\")\n",
        "  print(f\"[INFO] Source dir: {TARGET_DRIVE_PATH} -> Target dir: {local_dir}\")\n",
        "  !cp -r {TARGET_DRIVE_PATH} .\n",
        "  print(\"[INFO] Good to go!\")\n",
        "\n",
        "else:\n",
        "  # 5. If the files don't exist in Google Drive, download them\n",
        "  print(f\"[INFO] Target files not found in Google Drive.\")\n",
        "  print(f\"[INFO] Downloading the target files... this shouldn't take too long...\")\n",
        "  for file in TARGET_FILES:\n",
        "    # wget is short for \"world wide web get\", as in \"get a file from the web\"\n",
        "    # -nc or --no-clobber = don't download files that already exist locally\n",
        "    # -P = save the target file to a specified prefix, in our case, local_dir\n",
        "    !wget -nc {TARGET_URL}/{file} -P {local_dir} # the \"!\" means to execute the command on the command line rather than in Python\n",
        "\n",
        "  print(f\"[INFO] Saving the target files to Google Drive, so they can be loaded later...\")\n",
        "\n",
        "  # 6. Ensure target directory in Google Drive exists\n",
        "  TARGET_DRIVE_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "  # 7. Copy downloaded files to Google Drive (so we can use them later and not have to re-download them)\n",
        "  !cp -r {local_dir}/* {TARGET_DRIVE_PATH}/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRs1gwSLbMma",
        "outputId": "26e361eb-f6b7-4ffd-bddf-c7dc1fdb56a5"
      },
      "outputs": [],
      "source": [
        "if local_dir.exists():\n",
        "  print(str(local_dir) + \"/\")\n",
        "  for item in local_dir.iterdir():\n",
        "    print(\"  \", item.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SxChC5P7-5GP"
      },
      "outputs": [],
      "source": [
        "# Untar images, notes/tags:\n",
        "# -x = extract files from the zipped file\n",
        "# -v = verbose\n",
        "# -z = decompress files\n",
        "# -f = tell tar which file to deal with\n",
        "!tar -xf dog_vision_data/images.tar\n",
        "!tar -xf dog_vision_data/annotation.tar\n",
        "!tar -xf dog_vision_data/lists.tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzcNamgnjEbl",
        "outputId": "b824393e-d325-4917-e644-4b4a84503a89"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.listdir(\".\") # \".\" stands for \"here\" or \"current directory\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmVRq8MTLM5s",
        "outputId": "ba4b6a48-0966-4a8b-804c-c96748257bb2"
      },
      "outputs": [],
      "source": [
        "import scipy\n",
        "\n",
        "# Open lists of train and test .mat\n",
        "train_list = scipy.io.loadmat(\"train_list.mat\")\n",
        "test_list = scipy.io.loadmat(\"test_list.mat\")\n",
        "file_list = scipy.io.loadmat(\"file_list.mat\")\n",
        "\n",
        "# Let's inspect the output and type of the train_list\n",
        "train_list, type(train_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Q60719qWrR1",
        "outputId": "d78707aa-904a-4d1c-9905-09c865668962"
      },
      "outputs": [],
      "source": [
        "train_list.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9-hbGwwXe1m",
        "outputId": "71e83cdf-3712-4a3c-f907-9586b7315e91"
      },
      "outputs": [],
      "source": [
        "# Check the length of the file_list key\n",
        "print(f\"Number of files in training list: {len(train_list['file_list'])}\")\n",
        "print(f\"Number of files in testing list: {len(test_list['file_list'])}\")\n",
        "print(f\"Number of files in full list: {len(file_list['file_list'])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUFoCZyqYHdn",
        "outputId": "e03774ad-1f7d-4e6c-fd80-47615ebb74a5"
      },
      "outputs": [],
      "source": [
        "train_list['file_list']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "h8cjXRv1Y9_L",
        "outputId": "a62e15b9-bfaf-43d9-9d6c-247e2c4621f4"
      },
      "outputs": [],
      "source": [
        "# Get a single filename\n",
        "train_list['file_list'][0][0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsMM88RzNGfN",
        "outputId": "919e8398-d940-483b-f33d-523638fdbfac"
      },
      "outputs": [],
      "source": [
        "# Get a Python list of all file names for each list\n",
        "train_file_list = list([item[0][0] for item in train_list[\"file_list\"]])\n",
        "test_file_list = list([item[0][0] for item in test_list[\"file_list\"]])\n",
        "full_file_list = list([item[0][0] for item in file_list[\"file_list\"]])\n",
        "\n",
        "len(train_file_list), len(test_file_list), len(full_file_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1ZGHVHUZkqi",
        "outputId": "9c807f54-415c-48a3-9aee-db00aab722cd"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "random.sample(train_file_list, k=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXH4WsxLNOI6",
        "outputId": "a9b3ab11-42f9-4aa8-a4d3-e6fbdf47c586"
      },
      "outputs": [],
      "source": [
        "# How many files in the training set intersect with the testing set?\n",
        "len(set(train_file_list).intersection(test_file_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "IuNo8qqucyw8"
      },
      "outputs": [],
      "source": [
        "# Make an assertion statement to check there are no overlaps (try changing test_file_list to train_file_list to see how it works)\n",
        "assert len(set(train_file_list).intersection(test_file_list)) == 0, \"There are overlaps between the training and test set files, please check them.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rbSqiaqZNUVR",
        "outputId": "be12cd05-8fa5-4586-ba4d-bfb12988eb4e"
      },
      "outputs": [],
      "source": [
        "os.listdir(\"Annotation\")[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVB3Q7XMQuvn",
        "outputId": "fb84d978-1fff-4159-f306-182b56b61339"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "def count_subfolders(directory_path: str) -> int:\n",
        "    \"\"\"\n",
        "    Count the number of subfolders in a given directory.\n",
        "\n",
        "    Args:\n",
        "    directory_path (str): The path to the directory in which to count subfolders.\n",
        "\n",
        "    Returns:\n",
        "    int: The number of subfolders in the specified directory.\n",
        "\n",
        "    Examples:\n",
        "    >>> count_subfolders('/path/to/directory')\n",
        "    3  # if there are 3 subfolders in the specified directory\n",
        "    \"\"\"\n",
        "    return len([name for name in Path(directory_path).iterdir() if name.is_dir()])\n",
        "\n",
        "\n",
        "directory_path = \"Annotation\"\n",
        "folder_count = count_subfolders(directory_path)\n",
        "print(f\"Number of subfolders in {directory_path} directory: {folder_count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAQYFhLoUXuG"
      },
      "source": [
        "There are 120 subfolders of annotations, one for each class of dog we'd like to identify.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "EsY6d9u8UST7",
        "outputId": "c57ceac4-731b-4333-a23c-aae10817f3dc"
      },
      "outputs": [],
      "source": [
        "# View a single training file pathname\n",
        "train_file_list[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "zoHQiq8LYEW5",
        "outputId": "e8c2616c-7b98-4efa-e15e-7d00b207452f"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Image\n",
        "Image(Path(\"Images\", train_file_list[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygCyZMgMZfyc"
      },
      "source": [
        "We get an image of a dog"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbAkETNhbtiX",
        "outputId": "02fda3ff-5475-40d3-dd86-fd395e1e2435"
      },
      "outputs": [],
      "source": [
        "# Get a list of all image folders\n",
        "image_folders = os.listdir(\"Images\")\n",
        "image_folders[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "W4aZvkuAQW8z"
      },
      "outputs": [],
      "source": [
        "# Create folder name -> class name dict\n",
        "folder_to_class_name_dict = {}\n",
        "for folder_name in image_folders:\n",
        "  # Turn folder name into class_name\n",
        "  # E.g. \"n02089078-black-and-tan_coonhound\" -> \"black_and_tan_coonhound\"\n",
        "  # We'll split on the first \"-\" and join the rest of the string with \"_\" and then lower it\n",
        "  class_name = \"_\".join(folder_name.split(\"-\")[1:]).lower()\n",
        "  folder_to_class_name_dict[folder_name] = class_name\n",
        "\n",
        "# Make sure there are 120 entries in the dictionary\n",
        "assert len(folder_to_class_name_dict) == 120"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yL8DnJCkdM7C",
        "outputId": "05569d69-eadf-4386-f88f-5216f7a40c58"
      },
      "outputs": [],
      "source": [
        "list(folder_to_class_name_dict.items())[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4McaYooRb6L7",
        "outputId": "0e6aaec1-4f47-4b6d-dede-2b727e58bb32"
      },
      "outputs": [],
      "source": [
        "dog_names = sorted(list(folder_to_class_name_dict.values()))\n",
        "dog_names[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 807
        },
        "id": "dCGVcbiLcbmd",
        "outputId": "8a207ba4-8a79-4a00-b546-0f47775ba3e2"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Take in a select list of image paths\n",
        "def plot_10_random_images_from_path_list(path_list: List[Path],\n",
        "                                         extract_title: bool=True) -> None:\n",
        "  # 2. Set up a grid of plots\n",
        "  fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(20, 10))\n",
        "\n",
        "  # 3. Randomly sample 10 paths from the list\n",
        "  samples = random.sample(path_list, 10)\n",
        "\n",
        "  # 4. Iterate through the flattened axes and corresponding sample paths\n",
        "  for i, ax in enumerate(axes.flat):\n",
        "\n",
        "    # 5. Get the target sample path (e.g. \"Images/n02087394-Rhodesian_ridgeback/n02087394_1161.jpg\")\n",
        "    sample_path = samples[i]\n",
        "\n",
        "    # 6. Extract the parent directory name to use as the title (if necessary)\n",
        "    # (e.g. n02087394-Rhodesian_ridgeback/n02087394_1161.jpg -> n02087394-Rhodesian_ridgeback -> rhodesian_ridgeback)\n",
        "    if extract_title:\n",
        "      sample_title = folder_to_class_name_dict[sample_path.parent.stem]\n",
        "    else:\n",
        "      sample_title = sample_path.parent.stem\n",
        "\n",
        "    # 7. Read the image file and plot it on the corresponding axis\n",
        "    ax.imshow(plt.imread(sample_path))\n",
        "\n",
        "    # 8. Set the title of the axis and turn of the axis (for pretty plots)\n",
        "    ax.set_title(sample_title)\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "  # 9. Display the plot\n",
        "  plt.show()\n",
        "\n",
        "plot_10_random_images_from_path_list(path_list=[Path(\"Images\") / Path(file) for file in train_file_list])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Dak9dgOFS0UA"
      },
      "outputs": [],
      "source": [
        "# Create a dictionary of image counts\n",
        "from pathlib import Path\n",
        "from typing import List, Dict\n",
        "\n",
        "# 1. Take in a target directory\n",
        "def count_images_in_subdirs(target_directory: str) -> List[Dict[str, int]]:\n",
        "    \"\"\"\n",
        "    Counts the number of JPEG images in each subdirectory of the given directory.\n",
        "\n",
        "    Each subdirectory is assumed to represent a class, and the function counts\n",
        "    the number of '.jpg' files within each one. The result is a list of\n",
        "    dictionaries with the class name and corresponding image count.\n",
        "\n",
        "    Args:\n",
        "        target_directory (str): The path to the directory containing subdirectories.\n",
        "\n",
        "    Returns:\n",
        "        List[Dict[str, int]]: A list of dictionaries with 'class_name' and 'image_count' for each subdirectory.\n",
        "\n",
        "    Examples:\n",
        "        >>> count_images_in_subdirs('/path/to/directory')\n",
        "        [{'class_name': 'beagle', 'image_count': 50}, {'class_name': 'poodle', 'image_count': 60}]\n",
        "    \"\"\"\n",
        "    # 2. Create a list of all the subdirectoires in the target directory (these contain our images)\n",
        "    images_dir = Path(target_directory)\n",
        "    image_class_dirs = [directory for directory in images_dir.iterdir() if directory.is_dir()]\n",
        "\n",
        "    # 3. Create an empty list to append image counts to\n",
        "    image_class_counts = []\n",
        "\n",
        "    # 4. Iterate through all of the subdirectories\n",
        "    for image_class_dir in image_class_dirs:\n",
        "\n",
        "        # 5. Get the class name from image directory (e.g. \"Images/n02116738-African_hunting_dog\" -> \"n02116738-African_hunting_dog\")\n",
        "        class_name = image_class_dir.stem\n",
        "\n",
        "        # 6. Count the number of images in the target subdirectory\n",
        "        image_count = len(list(image_class_dir.rglob(\"*.jpg\")))  # get length all files with .jpg file extension\n",
        "\n",
        "        # 7. Append a dictionary of class name and image count to count list\n",
        "        image_class_counts.append({\"class_name\": class_name,\n",
        "                                   \"image_count\": image_count})\n",
        "\n",
        "    # 8. Return the list\n",
        "    return image_class_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOXutUuITq1G",
        "outputId": "d7256829-252f-4d26-d39f-13704a8a1e18"
      },
      "outputs": [],
      "source": [
        "image_class_counts = count_images_in_subdirs(\"Images\")\n",
        "image_class_counts[:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-i8JzYtoTjgZ",
        "outputId": "a6d7429f-1e51-4ab5-b428-6486cf304af7"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame\n",
        "import pandas as pd\n",
        "image_counts_df = pd.DataFrame(image_class_counts).sort_values(by=\"image_count\", ascending=False)\n",
        "image_counts_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Qf6l5_c8zOuA",
        "outputId": "d01f40d9-5caf-4d65-d417-c41bff11527e"
      },
      "outputs": [],
      "source": [
        "# Make class name column easier to read\n",
        "image_counts_df[\"class_name\"] = image_counts_df[\"class_name\"].map(folder_to_class_name_dict)\n",
        "image_counts_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        },
        "id": "VEHTtCQrgH9P",
        "outputId": "0933e76c-23aa-4db1-a745-73f7feb9dc5d"
      },
      "outputs": [],
      "source": [
        "# Turn the image counts DataFrame into a graph\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(14, 7))\n",
        "image_counts_df.plot(kind=\"bar\",\n",
        "                     x=\"class_name\",\n",
        "                     y=\"image_count\",\n",
        "                     legend=False,\n",
        "                     ax=plt.gca()) # plt.gca() = \"get current axis\", get the plt we setup above and put the data there\n",
        "\n",
        "# Add customization\n",
        "plt.ylabel(\"Image Count\")\n",
        "plt.title(\"Total Image Counts by Class\")\n",
        "plt.xticks(rotation=90, # Rotate the x labels for better visibility\n",
        "           fontsize=8) # Make the font size smaller for easier reading\n",
        "plt.tight_layout() # Ensure things fit nicely\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVwlnUwF1RwV"
      },
      "source": [
        "Each breed of dog has ~150 or more images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "n92bkA-l1hCQ",
        "outputId": "add56583-a630-4183-a58a-5322aaa614d6"
      },
      "outputs": [],
      "source": [
        "# Get various statistics about our data distribution\n",
        "image_counts_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYwlNwfjdMEp"
      },
      "source": [
        "## 4. Creating training and test data split directories\n",
        "\n",
        "After exploring the data, one of the next best things you can do is create experimental data splits.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P19tjiE7diKp",
        "outputId": "9eba58f6-76e7-4889-ec60-afb3470470d8"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Define the target directory for image splits to go\n",
        "images_split_dir = Path(\"images_split\")\n",
        "\n",
        "# Define the training and test directories\n",
        "train_dir = images_split_dir / \"train\"\n",
        "test_dir = images_split_dir / \"test\"\n",
        "\n",
        "# Using Path.mkdir with exist_ok=True ensures the directory is created only if it doesn't exist\n",
        "train_dir.mkdir(parents=True, exist_ok=True)\n",
        "test_dir.mkdir(parents=True, exist_ok=True)\n",
        "print(f\"Directory {train_dir} is exists.\")\n",
        "print(f\"Directory {test_dir} is exists.\")\n",
        "\n",
        "# Make a folder for each dog name\n",
        "for dog_name in dog_names:\n",
        "  # Make training dir folder\n",
        "  train_class_dir = train_dir / dog_name\n",
        "  train_class_dir.mkdir(parents=True, exist_ok=True)\n",
        "  # print(f\"Making directory: {train_class_dir}\")\n",
        "\n",
        "  # Make testing dir folder\n",
        "  test_class_dir = test_dir / dog_name\n",
        "  test_class_dir.mkdir(parents=True, exist_ok=True)\n",
        "  # print(f\"Making directory: {test_class_dir}\")\n",
        "\n",
        "# Make sure there is 120 subfolders in each\n",
        "assert count_subfolders(train_dir) == len(dog_names)\n",
        "assert count_subfolders(test_dir) == len(dog_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daOsSA9P-EIJ",
        "outputId": "f15fd38e-b32e-42c6-ecbe-fc069c5b52c1"
      },
      "outputs": [],
      "source": [
        "# See the first 10 directories in the training split dir\n",
        "sorted([str(dir_name) for dir_name in train_dir.iterdir() if dir_name.is_dir()])[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "zafX_YNjDqwO"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from shutil import copy2\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# 1. Take in a list of source files to copy and a target directory\n",
        "def copy_files_to_target_dir(file_list: list[str],\n",
        "                             target_dir: str,\n",
        "                             images_dir: str = \"Images\",\n",
        "                             verbose: bool = False) -> None:\n",
        "    \"\"\"\n",
        "    Copies a list of files from the images directory to a target directory.\n",
        "\n",
        "    Parameters:\n",
        "    file_list (list[str]): A list of file paths to copy.\n",
        "    target_dir (str): The destination directory path where files will be copied.\n",
        "    images_dir (str, optional): The directory path where the images are currently stored. Defaults to 'Images'.\n",
        "    verbose (bool, optional): If set to True, the function will print out the file paths as they are being copied. Defaults to False.\n",
        "\n",
        "    Returns:\n",
        "    None\n",
        "    \"\"\"\n",
        "    # 2. Iterate through source files\n",
        "    for file in tqdm(file_list):\n",
        "\n",
        "      # 3. Convert file path to a Path object\n",
        "      source_file_path = Path(images_dir) / Path(file)\n",
        "\n",
        "      # 4. Split the file path and create a Path object for the destination folder\n",
        "      # e.g. \"n02112018-Pomeranian\" -> \"pomeranian\"\n",
        "      file_class_name = folder_to_class_name_dict[Path(file).parts[0]]\n",
        "\n",
        "      # 5. Get the name of the target image\n",
        "      file_image_name = Path(file).name\n",
        "\n",
        "      # 6. Create the destination path\n",
        "      destination_file_path = Path(target_dir) / file_class_name / file_image_name\n",
        "\n",
        "      # 7. Ensure the destination directory exists (this is a safety check, can't copy an image to a file that doesn't exist)\n",
        "      destination_file_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "      # 8. Print out copy message if necessary\n",
        "      if verbose:\n",
        "        print(f\"[INFO] Copying: {source_file_path} to {destination_file_path}\")\n",
        "\n",
        "      # 9. Copy the original path to the destination path\n",
        "      copy2(src=source_file_path, dst=destination_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "394ca2713d0340b5ba3ff271610c8a1f",
            "baa87365978a44a3a2814f144d7c2f5f",
            "9edcb83b5da141218282afa44d6ee035",
            "9017cef924294485be6119a2896c47f5",
            "9e6bfd6d78564f06826763dfb9310eb9",
            "5ed6a20e243c47e690df62a9d997700b",
            "9b8053fa904f41bbb1a18a0f3ce36ed6",
            "027031949c084fd4b5046162c8a55693",
            "fa4affc1469043bf99deac511b2d981b",
            "55b864efb7d14a89bbb8c4eae39778ae",
            "6f7fe965c9124e66999ab3edad54661e"
          ]
        },
        "id": "21ejOD2bG0PA",
        "outputId": "728e39f0-fdc9-4021-cbb2-b1a9fc6bcab7"
      },
      "outputs": [],
      "source": [
        "# Copy training images from Images to images_split/train/...\n",
        "copy_files_to_target_dir(file_list=train_file_list,\n",
        "                         target_dir=train_dir,\n",
        "                         verbose=False) # set this to True to get an output of the copy process\n",
        "                                        # (warning: this will output a large amount of text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c6beff3bae9a42f0bf273322113c7033",
            "bbbe1e0f07e744508e7ece9ca2fb0cc6",
            "c5cdfdfabad84e5b83f0bd352692b04b",
            "119aa0b1ff834630bddc3873cc5b003e",
            "bd4f602f98a4467ba02aab3ab931f310",
            "513c4a7409ed4ee3a2677db2426ae266",
            "61ad70c7507c401797d67967f01406bb",
            "09258f93392b499ea4765a1eddbbd4b7",
            "fd130db283644091b35dab14749e7e24",
            "0397b96f147c4276872a0497a4634b81",
            "13405b043e8b47c08a281ab6e0d52e8b"
          ]
        },
        "id": "zjcmXv-RgDbx",
        "outputId": "37dc2f53-68f1-4e3d-9ac1-f60de6b7dc9b"
      },
      "outputs": [],
      "source": [
        "copy_files_to_target_dir(file_list=test_file_list,\n",
        "                         target_dir=test_dir,\n",
        "                         verbose=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "higIUiHAgDZs",
        "outputId": "8c985e84-95ce-42f4-dccc-bf1c850701bd"
      },
      "outputs": [],
      "source": [
        "# Get list of of all .jpg paths in train and test image directories\n",
        "train_image_paths = list(train_dir.rglob(\"*.jpg\"))\n",
        "test_image_paths = list(test_dir.rglob(\"*.jpg\"))\n",
        "\n",
        "# Make sure the number of images in the training and test directories equals the number of files in their original lists\n",
        "assert len(train_image_paths) == len(train_file_list)\n",
        "assert len(test_image_paths) == len(test_file_list)\n",
        "\n",
        "print(f\"Number of images in {train_dir}: {len(train_image_paths)}\")\n",
        "print(f\"Number of images in {test_dir}: {len(test_image_paths)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787
        },
        "id": "sOpZ20kIhqPM",
        "outputId": "4b278ec0-29fc-4a90-c411-9933280e55de"
      },
      "outputs": [],
      "source": [
        "# Plot 10 random images from the train_image_paths\n",
        "plot_10_random_images_from_path_list(path_list=train_image_paths,\n",
        "                                     extract_title=False) # don't need to extract the title since the image directories are already named simply"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUYK0GNLS7on"
      },
      "source": [
        "### Making a 10% training dataset split\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "06ZwrZtETNnU"
      },
      "outputs": [],
      "source": [
        "# Create train_10_percent directory\n",
        "train_10_percent_dir = images_split_dir / \"train_10_percent\"\n",
        "train_10_percent_dir.mkdir(parents=True, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqHQ-W80LoY2"
      },
      "source": [
        "Now we should have 3 split folders inside `images_split`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByXnVSagLvAQ",
        "outputId": "aadb34d1-596c-4b6f-8061-48e62b10046d"
      },
      "outputs": [],
      "source": [
        "os.listdir(images_split_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GY_q2OmbLsMh",
        "outputId": "c4f2fb4d-84e1-4f8a-af80-7dc3c1d9e6ea"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "# Set a random seed\n",
        "random.seed(42)\n",
        "\n",
        "# Get a 10% sample of the training image paths\n",
        "train_image_paths_random_10_percent = random.sample(population=train_image_paths,\n",
        "                                                    k=int(0.1*len(train_image_paths)))\n",
        "\n",
        "# Check how many image paths we got\n",
        "print(f\"Original number of training image paths: {len(train_image_paths)}\")\n",
        "print(f\"Number of 10% training image paths: {len(train_image_paths_random_10_percent)}\")\n",
        "print(\"First 5 random 10% training image paths:\")\n",
        "train_image_paths_random_10_percent[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "8134cbf9ab024f63bbd03c2cf2fe3889",
            "683df7bb7c574a039a9a6aaa4cdf6755",
            "8b1a533b53204395903745f47f23707e",
            "e0bfa4cecab64ba98f482d49b7798bfa",
            "c747f75944194202b91dcc3900c458b8",
            "5fabc898b9ca4af1bb8d8cf94541e8b3",
            "f1739aafd76c4a71b4ad93df9eec4aae",
            "82ffbca1e4014a4db0d07ba0b47fc75b",
            "4e8679790d734063a0e33acf9f325504",
            "2c898aa72e6940dd8c64a9dfd3d86927",
            "acd6cd597bf146f2b6d7235677661d8f"
          ]
        },
        "id": "XS2NaRmmLhwE",
        "outputId": "84821205-82fe-4758-dd9f-f406f2c6f2a6"
      },
      "outputs": [],
      "source": [
        "# Copy training 10% split images from images_split/train/ to images_split/train_10_percent/...\n",
        "for source_file_path in tqdm(train_image_paths_random_10_percent):\n",
        "\n",
        "  # Create the destination file path\n",
        "  destination_file_and_image_name = Path(*source_file_path.parts[-2:]) # \"images_split/train/yorkshire_terrier/n02094433_2223.jpg\" -> \"yorkshire_terrier/n02094433_2223.jpg\"\n",
        "  destination_file_path = train_10_percent_dir / destination_file_and_image_name # \"yorkshire_terrier/n02094433_2223.jpg\" -> \"images_split/train_10_percent/yorkshire_terrier/n02094433_2223.jpg\"\n",
        "\n",
        "  # If the target directory doesn't exist, make it\n",
        "  target_class_dir = destination_file_path.parent\n",
        "  if not target_class_dir.is_dir():\n",
        "    # print(f\"Making directory: {target_class_dir}\")\n",
        "    target_class_dir.mkdir(parents=True,\n",
        "                           exist_ok=True)\n",
        "\n",
        "  # print(f\"Copying: {source_file_path} to {destination_file_path}\")\n",
        "  copy2(src=source_file_path,\n",
        "        dst=destination_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHNxLWj0Lgs1"
      },
      "source": [
        "1200 images copied!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "uY3eIW4eguwl",
        "outputId": "a948b9e4-4767-49dc-acab-aa23b6b2528e"
      },
      "outputs": [],
      "source": [
        "# Count images in train_10_percent_dir\n",
        "train_10_percent_image_class_counts = count_images_in_subdirs(train_10_percent_dir)\n",
        "train_10_percent_image_class_counts_df = pd.DataFrame(train_10_percent_image_class_counts).sort_values(\"image_count\", ascending=True)\n",
        "train_10_percent_image_class_counts_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJcGXDJCR3np",
        "outputId": "66aa84cd-00a9-44fc-a0e3-222a299cc767"
      },
      "outputs": [],
      "source": [
        "# How many subfolders are there?\n",
        "print(len(train_10_percent_image_class_counts_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        },
        "id": "q1Jc_7DthoxD",
        "outputId": "7cdc8ea6-cb47-474a-8801-0358c2bc80ab"
      },
      "outputs": [],
      "source": [
        "# Plot distribution of train 10% dataset.\n",
        "plt.figure(figsize=(14, 7))\n",
        "train_10_percent_image_class_counts_df.plot(kind=\"bar\",\n",
        "                     x=\"class_name\",\n",
        "                     y=\"image_count\",\n",
        "                     legend=False,\n",
        "                     ax=plt.gca()) # plt.gca() = \"get current axis\", get the plt we setup above and put the data there\n",
        "\n",
        "# Add customization\n",
        "plt.title(\"Train 10 Percent Image Counts by Class\")\n",
        "plt.ylabel(\"Image Count\")\n",
        "plt.xticks(rotation=90, # Rotate the x labels for better visibility\n",
        "           fontsize=8) # Make the font size smaller for easier reading\n",
        "plt.tight_layout() # Ensure things fit nicely\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUlSbEnIh-PO"
      },
      "source": [
        "## 5. Turning datasets into TensorFlow Dataset(s)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KL_XKwgi-E9",
        "outputId": "810d4569-43c4-4447-9391-396d5a863764"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Create constants\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "SEED = 42\n",
        "\n",
        "# Create train 10% dataset\n",
        "train_10_percent_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    directory=train_10_percent_dir,\n",
        "    label_mode=\"categorical\", # turns labels into one-hot representations (e.g. [0, 0, 1, ..., 0, 0])\n",
        "    batch_size=BATCH_SIZE,\n",
        "    image_size=IMG_SIZE,\n",
        "    shuffle=True, # shuffle training datasets to prevent learning of order\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "# Create full train dataset\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    directory=train_dir,\n",
        "    label_mode=\"categorical\",\n",
        "    batch_size=BATCH_SIZE,\n",
        "    image_size=IMG_SIZE,\n",
        "    shuffle=True,\n",
        "    seed=SEED\n",
        ")\n",
        "\n",
        "# Create test dataset\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "    directory=test_dir,\n",
        "    label_mode=\"categorical\",\n",
        "    batch_size=BATCH_SIZE,\n",
        "    image_size=IMG_SIZE,\n",
        "    shuffle=False, # don't need to shuffle the test dataset (this makes evaluations easier)\n",
        "    seed=SEED\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHZM8AuAvbLZ",
        "outputId": "58c00131-9b52-49b2-e9d7-13849d3ab4a1"
      },
      "outputs": [],
      "source": [
        "train_10_percent_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RB9-Qe7ak8By",
        "outputId": "554ccc6b-7a78-4d25-f73f-5a6ed3312a24"
      },
      "outputs": [],
      "source": [
        "# What does a single batch look like?\n",
        "image_batch, label_batch = next(iter(train_ds))\n",
        "image_batch.shape, label_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XdbWWOd7lVpl",
        "outputId": "ac8cfeef-a1f0-4efa-fb88-903fa5cbc689"
      },
      "outputs": [],
      "source": [
        "# Get a single sample from a single batch\n",
        "print(f\"Single image tensor:\\n{image_batch[0]}\\n\")\n",
        "print(f\"Single label tensor: {label_batch[0]}\") # notice the 1 is the index of the target label (our labels are one-hot encoded)\n",
        "print(f\"Single sample class name: {dog_names[tf.argmax(label_batch[0])]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "Azcr6U1ozg_f",
        "outputId": "3989d0a7-5c32-44d0-b772-18e502158439"
      },
      "outputs": [],
      "source": [
        "plt.imshow(image_batch[0].numpy().astype(\"uint8\")) # convert tensor to uint8 to avoid matplotlib colour range issues\n",
        "plt.title(dog_names[tf.argmax(label_batch[0])])\n",
        "plt.axis(\"off\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "id": "oL4WJkOx0x90",
        "outputId": "ff44cc2d-01cb-40fd-b341-22e638839234"
      },
      "outputs": [],
      "source": [
        "# Create multiple subplots\n",
        "fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(20, 10))\n",
        "\n",
        "# Iterate through a single batch and plot images\n",
        "for images, labels in train_ds.take(count=1): # note: because our training data is shuffled, each \"take\" will be different\n",
        "  for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    ax.set_title(dog_names[tf.argmax(labels[i])])\n",
        "    ax.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoG81fLHTCtA",
        "outputId": "d7320dd9-d1bc-4bf6-e9bc-e253bf7b4ef9"
      },
      "outputs": [],
      "source": [
        "# Get the first 5 file paths of the training dataset\n",
        "train_ds.file_paths[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saFXwH7DkpBs",
        "outputId": "42e11362-1ac5-430c-de2b-344632211407"
      },
      "outputs": [],
      "source": [
        "# Get the class names TensorFlow has read from the target directory\n",
        "class_names = train_ds.class_names\n",
        "class_names[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "d3xVUa0_kl5i"
      },
      "outputs": [],
      "source": [
        "assert set(train_10_percent_ds.class_names) == set(train_ds.class_names) == set(test_ds.class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "9hlrBy59lzQi"
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE # let TensorFlow find the best values to use automatically\n",
        "\n",
        "# Shuffle and optimize performance on training datasets\n",
        "# Note: these methods can be chained together and will have the same effect as calling them individually\n",
        "train_10_percent_ds = train_10_percent_ds.cache().shuffle(buffer_size=10*BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "train_ds = train_ds.cache().shuffle(buffer_size=100*BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# Don't need to shuffle test datasets (for easier evaluation)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "teWeV33en5Cq"
      },
      "source": [
        "## 6. Creating a neural network with TensorFlow\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "S1tWQe3dHfeZ"
      },
      "outputs": [],
      "source": [
        "# Create the input shape to our model\n",
        "INPUT_SHAPE = (*IMG_SIZE, 3)\n",
        "\n",
        "base_model = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(\n",
        "    include_top=True, # do want to include the top layer? (ImageNet has 1000 classes, so the top layer is formulated for this, we want to create our own top layer)\n",
        "    include_preprocessing=True, # do we want the network to preprocess our data into the right format for us? (yes)\n",
        "    weights=\"imagenet\", # do we want the network to come with pretrained weights? (yes)\n",
        "    input_shape=INPUT_SHAPE # what is the input shape of our data we're going to pass to the network? (224, 224, 3) -> (height, width, colour_channels)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "3IQe-aO4aOGp",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Note: Uncomment to see full output\n",
        "# base_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTJI8c-FxGMm",
        "outputId": "1ef66f01-12b1-47ff-c77e-498aca2b14fe"
      },
      "outputs": [],
      "source": [
        "# Count the number of layers\n",
        "print(f\"Number of layers in base_model: {len(base_model.layers)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekRXrqUnNwBD",
        "outputId": "2a4077b7-a223-486a-f099-d0d4c33ea2e0"
      },
      "outputs": [],
      "source": [
        "# Check the input shape of our model\n",
        "base_model.input_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fEsmGs-ZNt4K",
        "outputId": "7019eadf-5f7b-4563-a122-01d5fa85f3d4"
      },
      "outputs": [],
      "source": [
        "# Check the model's output shape\n",
        "base_model.output_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKBMQdhMwvUp",
        "outputId": "c2250b85-5c60-4a3d-f90e-2566e4fcea98"
      },
      "outputs": [],
      "source": [
        "# Create a base model with no top\n",
        "base_model = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(\n",
        "    include_top=False, # don't include the top layer (we want to make our own top layer)\n",
        "    include_preprocessing=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=INPUT_SHAPE,\n",
        ")\n",
        "\n",
        "# Check the output shape\n",
        "base_model.output_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ls6un2N3w4n3",
        "outputId": "35f0ea26-a231-44f5-8b14-17207127681d"
      },
      "outputs": [],
      "source": [
        "# Count the number of layers\n",
        "print(f\"Number of layers in base_model: {len(base_model.layers)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKeA-bD73_M8",
        "outputId": "25f049c4-87bb-4ed0-d7fc-60d72e093b86"
      },
      "outputs": [],
      "source": [
        "# Check the number of parameters in our model\n",
        "base_model.count_params()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cb4qG9kS2hxR",
        "outputId": "228fa0d4-f6e9-47b7-ba2e-3da3de24481f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def count_parameters(model, print_output=True):\n",
        "  \"\"\"\n",
        "  Counts the number of trainable, non-trainable and total parameters of a given model.\n",
        "  \"\"\"\n",
        "  trainable_parameters = np.sum([np.prod(layer.shape) for layer in model.trainable_weights])\n",
        "  non_trainable_parameters = np.sum([np.prod(layer.shape) for layer in model.non_trainable_weights])\n",
        "  total_parameters = trainable_parameters + non_trainable_parameters\n",
        "  if print_output:\n",
        "    print(f\"Model {model.name} parameter counts:\")\n",
        "    print(f\"Total parameters: {total_parameters}\")\n",
        "    print(f\"Trainable parameters: {trainable_parameters}\")\n",
        "    print(f\"Non-trainable parameters: {non_trainable_parameters}\")\n",
        "  else:\n",
        "    return total_parameters, trainable_parameters, non_trainable_parameters\n",
        "\n",
        "count_parameters(model=base_model, print_output=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uk1nb0XDIiQ",
        "outputId": "18725eb9-1259-48e5-e4b1-e181a8a4973d"
      },
      "outputs": [],
      "source": [
        "# Freeze the base model\n",
        "base_model.trainable = False\n",
        "base_model.trainable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B42oNpvFDQ8J",
        "outputId": "ae8a262b-64bc-4a15-9c11-5bec112ea5d1"
      },
      "outputs": [],
      "source": [
        "count_parameters(model=base_model, print_output=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipVCa19zJcZ4",
        "outputId": "ee4c75a1-2442-4fc9-cc3b-b9fa566b2b9e"
      },
      "outputs": [],
      "source": [
        "# Current image shape\n",
        "shape_of_image_without_batch = image_batch[0].shape\n",
        "\n",
        "# Add a batch dimension to our single image\n",
        "shape_of_image_with_batch = tf.expand_dims(input=image_batch[0], axis=0).shape\n",
        "\n",
        "print(f\"Shape of image without batch: {shape_of_image_without_batch}\")\n",
        "print(f\"Shape of image with batch: {shape_of_image_with_batch}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xze4u_gJJVbl",
        "outputId": "348f80c2-fd0f-4097-ec39-04f12fcaa1a8"
      },
      "outputs": [],
      "source": [
        "# Extract features from a single image using our base model\n",
        "feature_extraction = base_model(tf.expand_dims(image_batch[0], axis=0))\n",
        "feature_extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JT0o4xnjuBnM",
        "outputId": "4d987f66-fdf4-47e8-ee1b-1651051454c6"
      },
      "outputs": [],
      "source": [
        "# Check shape of feature extraction\n",
        "feature_extraction.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COCP3-KzuWHU",
        "outputId": "daf6c933-77c5-413f-becd-a462b0eebc90"
      },
      "outputs": [],
      "source": [
        "num_input_features = 224*224*3\n",
        "feature_extraction_features = 1*7*7*1280\n",
        "\n",
        "# Calculate the compression ratio\n",
        "num_input_features / feature_extraction_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOV-hBw2abNP",
        "outputId": "1a033b86-b23d-40e1-c7be-d2b3c5a8e032"
      },
      "outputs": [],
      "source": [
        "# Turn feature extraction into a feature vector\n",
        "feature_vector = tf.keras.layers.GlobalAveragePooling2D()(feature_extraction) # pass feature_extraction to the pooling layer\n",
        "feature_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euYJU1yXyvAe",
        "outputId": "147eb3be-b15f-41b8-ff15-254581708f69"
      },
      "outputs": [],
      "source": [
        "# Check out the feature vector shape\n",
        "feature_vector.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f1_XXaOyzQk",
        "outputId": "0147bd01-5716-492d-f8eb-40647858f5fc"
      },
      "outputs": [],
      "source": [
        "# Compare the reduction\n",
        "num_input_features = 224*224*3\n",
        "feature_extraction_features = 1*7*7*1280\n",
        "feature_vector_features = 1*1280\n",
        "\n",
        "print(f\"Input -> feature extraction reduction factor: {num_input_features / feature_extraction_features}\")\n",
        "print(f\"Feature extraction -> feature vector reduction factor: {feature_extraction_features / feature_vector_features}\")\n",
        "print(f\"Input -> feature extraction -> feature vector reduction factor: {num_input_features / feature_vector_features}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfQ5pc92iy4t",
        "outputId": "d0a4b762-1199-4952-8cb2-d210e78ba9b3"
      },
      "outputs": [],
      "source": [
        "# Create a base model with no top and a pooling layer built-in\n",
        "base_model = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=INPUT_SHAPE,\n",
        "    pooling=\"avg\", # can also use \"max\"\n",
        "    include_preprocessing=True,\n",
        ")\n",
        "\n",
        "# Check the summary (optional)\n",
        "# base_model.summary()\n",
        "\n",
        "# Check the output shape\n",
        "base_model.output_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbouPjq6iwj_",
        "outputId": "6ed73200-5cd9-435c-9c5e-97e3df6a99a0"
      },
      "outputs": [],
      "source": [
        "# Freeze the base weights\n",
        "base_model.trainable = False\n",
        "\n",
        "# Count the parameters\n",
        "count_parameters(model=base_model, print_output=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0aowzCmlgAY",
        "outputId": "8630dbab-6599-421c-fb13-e5b323e9b499"
      },
      "outputs": [],
      "source": [
        "# Get a feature vector of a single image (don't forget to add a batch dimension)\n",
        "feature_vector_2 = base_model(tf.expand_dims(image_batch[0], axis=0))\n",
        "feature_vector_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sjoz4Yt2lyHl",
        "outputId": "315fdabf-57da-4a96-bc56-e011f892d98e"
      },
      "outputs": [],
      "source": [
        "# Compare the two feature vectors\n",
        "np.all(feature_vector == feature_vector_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1YOMjfoN0_T"
      },
      "outputs": [],
      "source": [
        "# 1. Create input layer\n",
        "inputs = tf.keras.Input(shape=INPUT_SHAPE)\n",
        "\n",
        "# 2. Create hidden layer\n",
        "x = base_model(inputs, training=False)\n",
        "\n",
        "# 3. Create the output layer\n",
        "outputs = tf.keras.layers.Dense(units=len(class_names), # one output per class\n",
        "                                activation=\"softmax\",\n",
        "                                name=\"output_layer\")(x)\n",
        "\n",
        "# 4. Connect the inputs and outputs together\n",
        "functional_model = tf.keras.Model(inputs=inputs,\n",
        "                                  outputs=outputs,\n",
        "                                  name=\"functional_model\")\n",
        "\n",
        "# Get a model summary\n",
        "functional_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2aX4cbmf8sm"
      },
      "outputs": [],
      "source": [
        "# Pass a single image through our functional_model\n",
        "single_image_output_functional = functional_model(single_image_input)\n",
        "\n",
        "# Find the index with the highest value\n",
        "highest_value_index_functional_model_output = np.argmax(single_image_output_functional)\n",
        "highest_value_functional_model_output = np.max(single_image_output_functional)\n",
        "\n",
        "highest_value_index_functional_model_output, highest_value_functional_model_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLhWvWknqhG4"
      },
      "outputs": [],
      "source": [
        "def create_model(include_top: bool = False,\n",
        "                 num_classes: int = 1000,\n",
        "                 input_shape: tuple[int, int, int] = (224, 224, 3),\n",
        "                 include_preprocessing: bool = True,\n",
        "                 trainable: bool = False,\n",
        "                 dropout: float = 0.2,\n",
        "                 model_name: str = \"model\") -> tf.keras.Model:\n",
        "  \"\"\"\n",
        "  Create an EfficientNetV2 B0 feature extractor model with a custom classifier layer.\n",
        "\n",
        "  Args:\n",
        "      include_top (bool, optional): Whether to include the top (classifier) layers of the model.\n",
        "      num_classes (int, optional): Number of output classes for the classifier layer.\n",
        "      input_shape (tuple[int, int, int], optional): Input shape for the model's images (height, width, channels).\n",
        "      include_preprocessing (bool, optional): Whether to include preprocessing layers for image normalization.\n",
        "      trainable (bool, optional): Whether to make the base model trainable.\n",
        "      dropout (float, optional): Dropout rate for the global average pooling layer.\n",
        "      model_name (str, optional): Name for the created model.\n",
        "\n",
        "  Returns:\n",
        "      tf.keras.Model: A TensorFlow Keras model with the specified configuration.\n",
        "  \"\"\"\n",
        "  # Create base model\n",
        "  base_model = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(\n",
        "    include_top=include_top,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=input_shape,\n",
        "    include_preprocessing=include_preprocessing,\n",
        "    pooling=\"avg\" # Can use this instead of adding tf.keras.layers.GlobalPooling2D() to the model\n",
        "    # pooling=\"max\" # Can use this instead of adding tf.keras.layers.MaxPooling2D() to the model\n",
        "  )\n",
        "\n",
        "  # Freeze the base model (if necessary)\n",
        "  base_model.trainable = trainable\n",
        "\n",
        "  # Create input layer\n",
        "  inputs = tf.keras.Input(shape=input_shape, name=\"input_layer\")\n",
        "\n",
        "  # Create model backbone (middle/hidden layers)\n",
        "  x = base_model(inputs, training=trainable)\n",
        "  # x = tf.keras.layers.GlobalAveragePooling2D()(x) # note: you should include pooling here if not using `pooling=\"avg\"`\n",
        "  # x = tf.keras.layers.Dropout(0.2)(x) # optional regularization layer (search \"dropout\" for more)\n",
        "\n",
        "  # Create output layer (also known as \"classifier\" layer)\n",
        "  outputs = tf.keras.layers.Dense(units=num_classes,\n",
        "                                  activation=\"softmax\",\n",
        "                                  name=\"output_layer\")(x)\n",
        "\n",
        "  # Connect input and output layer\n",
        "  model = tf.keras.Model(inputs=inputs,\n",
        "                         outputs=outputs,\n",
        "                         name=model_name)\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihLmnBvljkq2"
      },
      "outputs": [],
      "source": [
        "# Create a model\n",
        "model_0 = create_model(num_classes=len(class_names))\n",
        "model_0.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8c6lCaMaDuhq"
      },
      "outputs": [],
      "source": [
        "for layer in model_0.layers:\n",
        "  print(layer.name, layer.trainable)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVPLT6dsvXvN"
      },
      "source": [
        "## 7. Model 0 - Train a model on 10% of the training data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8wGF_nXHxsk"
      },
      "outputs": [],
      "source": [
        "# 1. Create model\n",
        "model_0 = create_model(num_classes=len(class_names),\n",
        "                       model_name=\"model_0\")\n",
        "\n",
        "model_0.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZBFpQAYuFH9"
      },
      "outputs": [],
      "source": [
        "# Create optimizer (short version)\n",
        "optimizer = \"adam\"\n",
        "\n",
        "# The above line is the same as below\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmOlIe67tLtw"
      },
      "outputs": [],
      "source": [
        "# Check that our labels are one-hot encoded\n",
        "label_batch[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNEJlM-IuQL4"
      },
      "outputs": [],
      "source": [
        "# Create our loss function\n",
        "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False) # use from_logits=False if using an activation function in final layer of model (default)\n",
        "loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzWRBDkkalkq"
      },
      "outputs": [],
      "source": [
        "# Create list of evaluation metrics\n",
        "metrics = [\"accuracy\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfNo3j-2bRTz"
      },
      "outputs": [],
      "source": [
        "# Compile model with shortcuts (faster to write code but less customizable)\n",
        "model_0.compile(optimizer=\"adam\",\n",
        "                loss=\"categorical_crossentropy\",\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Compile model with classes (will do the same as above)\n",
        "model_0.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "                metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPA9zfMSJ41u"
      },
      "source": [
        "It might take a bit more time than expected\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PoO48PLdBHT"
      },
      "outputs": [],
      "source": [
        "# Fit model_0 for 5 epochs\n",
        "epochs = 5\n",
        "history_0 = model_0.fit(x=train_10_percent_ds,\n",
        "                        epochs=epochs,\n",
        "                        validation_data=test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdDhrasey9QX"
      },
      "source": [
        "## 8. Putting it all together: create, compile, fit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCelV7z1zZDS"
      },
      "outputs": [],
      "source": [
        "# 1. Create a model\n",
        "model_0 = create_model(num_classes=len(dog_names))\n",
        "\n",
        "# 2. Compile the model\n",
        "model_0.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                loss=\"categorical_crossentropy\",\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "epochs = 5\n",
        "history_0 = model_0.fit(x=train_10_percent_ds,\n",
        "                        epochs=epochs,\n",
        "                        validation_data=test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5P9oMxTViMH"
      },
      "outputs": [],
      "source": [
        "# Inspect History.history attribute for model_0\n",
        "history_0.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unxxELrtjHdo"
      },
      "outputs": [],
      "source": [
        "def plot_model_loss_curves(history: tf.keras.callbacks.History) -> None:\n",
        "  \"\"\"Takes a History object and plots loss and accuracy curves.\"\"\"\n",
        "\n",
        "  # Get the accuracy values\n",
        "  acc = history.history[\"accuracy\"]\n",
        "  val_acc = history.history[\"val_accuracy\"]\n",
        "\n",
        "  # Get the loss values\n",
        "  loss = history.history[\"loss\"]\n",
        "  val_loss = history.history[\"val_loss\"]\n",
        "\n",
        "  # Get the number of epochs\n",
        "  epochs_range = range(len(acc))\n",
        "\n",
        "  # Create accuracy curves plot\n",
        "  plt.figure(figsize=(14, 7))\n",
        "  plt.subplot(1, 2, 1)\n",
        "  plt.plot(epochs_range, acc, label=\"Training Accuracy\")\n",
        "  plt.plot(epochs_range, val_acc, label=\"Validation Accuracy\")\n",
        "  plt.legend(loc=\"lower right\")\n",
        "  plt.title(\"Training and Validation Accuracy\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "\n",
        "  # Create loss curves plot\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.plot(epochs_range, loss, label=\"Training Loss\")\n",
        "  plt.plot(epochs_range, val_loss, label=\"Validation Loss\")\n",
        "  plt.legend(loc=\"upper right\")\n",
        "  plt.title(\"Training and Validation Loss\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Loss\")\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "plot_model_loss_curves(history=history_0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JcO1tdoOakV"
      },
      "outputs": [],
      "source": [
        "# Evaluate model_0, see: https://www.tensorflow.org/api_docs/python/tf/keras/Model#evaluate\n",
        "model_0_results = model_0.evaluate(x=test_ds)\n",
        "model_0_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Op0olpS2azjI"
      },
      "outputs": [],
      "source": [
        "# Get our model's metrics names\n",
        "model_0.metrics_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ycprd6gfi7_I"
      },
      "source": [
        "## 9. Model 1 - Train a model on 100% of the training data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGXws3Dgi7vF"
      },
      "outputs": [],
      "source": [
        "# 1. Create model_1 (the next iteration of model_0)\n",
        "model_1 = create_model(num_classes=len(class_names),\n",
        "                       model_name=\"model_1\")\n",
        "\n",
        "# 2. Compile model\n",
        "model_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                loss=\"categorical_crossentropy\",\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# 3. Fit model\n",
        "epochs=5\n",
        "history_1 = model_1.fit(x=train_ds,\n",
        "                        epochs=epochs,\n",
        "                        validation_data=test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ODDuhIgO30W"
      },
      "outputs": [],
      "source": [
        "# Plot model_1 loss curves\n",
        "plot_model_loss_curves(history=history_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLBiBCC2O6u6"
      },
      "outputs": [],
      "source": [
        "# Evaluate model_1\n",
        "model_1_results = model_1.evaluate(test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_6cy_dQTxeY"
      },
      "source": [
        "## 10. Make and evaluate predictions of the best model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhTvmaaZT0nC"
      },
      "outputs": [],
      "source": [
        "# This will output logits (as long as softmax activation isn't in the model)\n",
        "test_preds = model_1.predict(test_ds)\n",
        "\n",
        "# Note: If not using activation=\"softmax\" in last layer of model, may need to turn them into prediction probabilities (easier to understand)\n",
        "# test_preds = tf.keras.activations.softmax(tf.constant(test_preds), axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2Ey_czak9sG"
      },
      "outputs": [],
      "source": [
        "test_preds.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fW8dzzHMk__z"
      },
      "outputs": [],
      "source": [
        "# Get a \"random\" variable between all of the test samples\n",
        "random.seed(42)\n",
        "random_test_index = random.randint(0, test_preds.shape[0] - 1)\n",
        "print(f\"[INFO] Random test index: {random_test_index}\")\n",
        "\n",
        "# Inspect a single test prediction sample\n",
        "random_test_pred_sample = test_preds[random_test_index]\n",
        "\n",
        "print(f\"[INFO] Random test pred sample shape: {random_test_pred_sample.shape}\")\n",
        "print(f\"[INFO] Random test pred sample argmax: {tf.argmax(random_test_pred_sample)}\")\n",
        "print(f\"[INFO] Random test pred sample label: {dog_names[tf.argmax(random_test_pred_sample)]}\")\n",
        "print(f\"[INFO] Random test pred sample max prediction probability: {tf.reduce_max(random_test_pred_sample)}\")\n",
        "print(f\"[INFO] Random test pred sample prediction probability values:\\n{random_test_pred_sample}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1seOl9JlHgj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Extract test images and labels from test_ds\n",
        "test_ds_images = np.concatenate([images for images, labels in test_ds], axis=0)\n",
        "test_ds_labels = np.concatenate([labels for images, labels in test_ds], axis=0)\n",
        "\n",
        "# How many images and labels do we have?\n",
        "len(test_ds_images), len(test_ds_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "960o675Q1M55"
      },
      "outputs": [],
      "source": [
        "# Set target index\n",
        "target_index = 42 # try changing this to another value and seeing how the model performs on other samples\n",
        "\n",
        "# Get test image\n",
        "test_image = test_ds_images[target_index]\n",
        "\n",
        "# Get truth label (index of max in test label)\n",
        "test_image_truth_label = class_names[tf.argmax(test_ds_labels[target_index])]\n",
        "\n",
        "# Get prediction probabilities\n",
        "test_image_pred_probs = test_preds[target_index]\n",
        "\n",
        "# Get index of class with highest prediction probability\n",
        "test_image_pred_class = class_names[tf.argmax(test_image_pred_probs)]\n",
        "\n",
        "# Plot the image\n",
        "plt.figure(figsize=(5, 4))\n",
        "plt.imshow(test_image.astype(\"uint8\"))\n",
        "\n",
        "# Create sample title with prediction probability value\n",
        "title = f\"\"\"True: {test_image_truth_label}\n",
        "Pred: {test_image_pred_class}\n",
        "Prob: {np.max(test_image_pred_probs):.2f}\"\"\"\n",
        "\n",
        "# Colour the title based on correctness of pred\n",
        "plt.title(title,\n",
        "          color=\"green\" if test_image_truth_label == test_image_pred_class else \"red\")\n",
        "plt.axis(\"off\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvAFP-8zl6In"
      },
      "outputs": [],
      "source": [
        "# Choose a random 10 indexes from the test data and compare the values\n",
        "import random\n",
        "\n",
        "random.seed(42) # try changing the random seed or commenting it out for different values\n",
        "random_indexes = random.sample(range(len(test_ds_images)), 10)\n",
        "\n",
        "# Create a plot with multiple subplots\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 7))\n",
        "\n",
        "# Loop through the axes of the plot\n",
        "for i, ax in enumerate(axes.flatten()):\n",
        "  target_index = random_indexes[i] # get a random index (this is another reason we didn't shuffle the test set)\n",
        "\n",
        "  # Get relevant target image, label, prediction and prediction probabilities\n",
        "  test_image = test_ds_images[target_index]\n",
        "  test_image_truth_label = class_names[tf.argmax(test_ds_labels[target_index])]\n",
        "  test_image_pred_probs = test_preds[target_index]\n",
        "  test_image_pred_class = class_names[tf.argmax(test_image_pred_probs)]\n",
        "\n",
        "  # Plot the image\n",
        "  ax.imshow(test_image.astype(\"uint8\"))\n",
        "\n",
        "  # Create sample title\n",
        "  title = f\"\"\"True: {test_image_truth_label}\n",
        "  Pred: {test_image_pred_class}\n",
        "  Prob: {np.max(test_image_pred_probs):.2f}\"\"\"\n",
        "\n",
        "  # Colour the title based on correctness of pred\n",
        "  ax.set_title(title,\n",
        "               color=\"green\" if test_image_truth_label == test_image_pred_class else \"red\")\n",
        "  ax.axis(\"off\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANh2z09_N-Xm"
      },
      "outputs": [],
      "source": [
        "# Get argmax labels of test predictions and test ground truth\n",
        "test_preds_labels = test_preds.argmax(axis=-1)\n",
        "test_ds_labels_argmax = test_ds_labels.argmax(axis=-1)\n",
        "\n",
        "# Get highest prediction probability of test predictions\n",
        "test_pred_probs_max = tf.reduce_max(test_preds, axis=-1).numpy() # extract NumPy since pandas doesn't handle TensorFlow Tensors\n",
        "\n",
        "# Create DataFram of test results\n",
        "test_results_df = pd.DataFrame({\"test_pred_label\": test_preds_labels,\n",
        "                                \"test_pred_prob\": test_pred_probs_max,\n",
        "                                \"test_pred_class_name\": [class_names[test_pred_label] for test_pred_label in test_preds_labels],\n",
        "                                \"test_truth_label\": test_ds_labels_argmax,\n",
        "                                \"test_truth_class_name\": [class_names[test_truth_label] for test_truth_label in test_ds_labels_argmax]})\n",
        "\n",
        "# Create a column whether or not the prediction matches the label\n",
        "test_results_df[\"correct\"] = test_results_df[\"test_pred_class_name\"] == test_results_df[\"test_truth_class_name\"]\n",
        "\n",
        "test_results_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNMgjujPTNyH"
      },
      "outputs": [],
      "source": [
        "# Calculate accuracy per class\n",
        "accuracy_per_class = test_results_df.groupby(\"test_truth_class_name\")[\"correct\"].mean()\n",
        "\n",
        "# Create new DataFrame to sort classes by accuracy\n",
        "accuracy_per_class_df = pd.DataFrame(accuracy_per_class).reset_index().sort_values(\"correct\", ascending=False)\n",
        "accuracy_per_class_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1j5b80CDeNV6"
      },
      "outputs": [],
      "source": [
        "# Let's create a horizontal bar chart to replicate a similar plot to the original Stanford Dogs page\n",
        "plt.figure(figsize=(10, 17))\n",
        "plt.barh(y=accuracy_per_class_df[\"test_truth_class_name\"],\n",
        "         width=accuracy_per_class_df[\"correct\"])\n",
        "plt.xlabel(\"Accuracy\")\n",
        "plt.ylabel(\"Class Name\")\n",
        "plt.title(\"Dog Vision Accuracy per Class\")\n",
        "plt.ylim(-0.5, len(accuracy_per_class_df[\"test_truth_class_name\"]) - 0.5)  # Adjust y-axis limits to reduce white space\n",
        "plt.gca().invert_yaxis()  # This will display the first class at the top\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ffG0ITvE_Gn"
      },
      "outputs": [],
      "source": [
        "# Inspecting our worst performing classes (note how only a couple of classes perform at ~55% accuracy or below)\n",
        "accuracy_per_class_df.tail()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YX2KDkUVXx5"
      },
      "source": [
        "### Finding the most wrong examples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLCFAHnqVKMS"
      },
      "outputs": [],
      "source": [
        "# Get most wrong\n",
        "top_100_most_wrong = test_results_df[test_results_df[\"correct\"] == 0].sort_values(\"test_pred_prob\", ascending=False)[:100]\n",
        "top_100_most_wrong.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OS-ldZfrV6ie"
      },
      "outputs": [],
      "source": [
        "# Get 10 random indexes of \"most wrong\" predictions\n",
        "top_100_most_wrong.sample(n=10).index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hIofeUwHVuJC"
      },
      "outputs": [],
      "source": [
        "# Choose a random 10 indexes from the test data and compare the values\n",
        "import random\n",
        "\n",
        "random_most_wrong_indexes = top_100_most_wrong.sample(n=10).index\n",
        "\n",
        "# Iterate through test results and plot them\n",
        "# Note: This is why we don't shuffle the test data, so that it's in original order when we evaluate it.\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 7))\n",
        "for i, ax in enumerate(axes.flatten()):\n",
        "  target_index = random_most_wrong_indexes[i]\n",
        "\n",
        "  # Get relevant target image, label, prediction and prediction probabilities\n",
        "  test_image = test_ds_images[target_index]\n",
        "  test_image_truth_label = class_names[tf.argmax(test_ds_labels[target_index])]\n",
        "  test_image_pred_probs = test_preds[target_index]\n",
        "  test_image_pred_class = class_names[tf.argmax(test_image_pred_probs)]\n",
        "\n",
        "  # Plot the image\n",
        "  ax.imshow(test_image.astype(\"uint8\"))\n",
        "\n",
        "  # Create sample title\n",
        "  title = f\"\"\"True: {test_image_truth_label}\n",
        "  Pred: {test_image_pred_class}\n",
        "  Prob: {np.max(test_image_pred_probs):.2f}\"\"\"\n",
        "\n",
        "  # Colour the title based on correctness of pred\n",
        "  ax.set_title(title,\n",
        "               color=\"green\" if test_image_truth_label == test_image_pred_class else \"red\",\n",
        "               fontsize=10)\n",
        "  ax.axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9JS1CbnYBqO"
      },
      "source": [
        "### Create a confusion matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rojnFhUSYDnU"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Create a confusion matrix\n",
        "confusion_matrix_dog_preds = confusion_matrix(y_true=test_ds_labels_argmax, # requires all labels to be in same format (e.g. not one-hot)\n",
        "                                              y_pred=test_preds_labels)\n",
        "# Create a confusion matrix plot\n",
        "confusion_matrix_display = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix_dog_preds,\n",
        "                                                  display_labels=class_names)\n",
        "fig, ax = plt.subplots(figsize=(25, 25))\n",
        "ax.set_title(\"Dog Vision Confusion Matrix\")\n",
        "confusion_matrix_display.plot(xticks_rotation=\"vertical\",\n",
        "                              cmap=\"Blues\",\n",
        "                              colorbar=False,\n",
        "                              ax=ax);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXOCxxOJPeDL"
      },
      "source": [
        "## 11. Save and load the best model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTm-THXeXruu"
      },
      "outputs": [],
      "source": [
        "# Save the model to .keras\n",
        "model_save_path = \"dog_vision_model.keras\"\n",
        "model_1.save(filepath=model_save_path,\n",
        "             save_format=\"keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_dch58qP8LV"
      },
      "outputs": [],
      "source": [
        "# Load the model\n",
        "loaded_model = tf.keras.models.load_model(filepath=model_save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y2k43_YYplvB"
      },
      "outputs": [],
      "source": [
        "# Evaluate the loaded model\n",
        "loaded_model_results = loaded_model.evaluate(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBKSPv1gQExZ"
      },
      "outputs": [],
      "source": [
        "assert model_1_results == loaded_model_results"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "027031949c084fd4b5046162c8a55693": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0397b96f147c4276872a0497a4634b81": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09258f93392b499ea4765a1eddbbd4b7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "119aa0b1ff834630bddc3873cc5b003e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0397b96f147c4276872a0497a4634b81",
            "placeholder": "​",
            "style": "IPY_MODEL_13405b043e8b47c08a281ab6e0d52e8b",
            "value": " 8580/8580 [00:02&lt;00:00, 3009.54it/s]"
          }
        },
        "13405b043e8b47c08a281ab6e0d52e8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c898aa72e6940dd8c64a9dfd3d86927": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "394ca2713d0340b5ba3ff271610c8a1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_baa87365978a44a3a2814f144d7c2f5f",
              "IPY_MODEL_9edcb83b5da141218282afa44d6ee035",
              "IPY_MODEL_9017cef924294485be6119a2896c47f5"
            ],
            "layout": "IPY_MODEL_9e6bfd6d78564f06826763dfb9310eb9"
          }
        },
        "4e8679790d734063a0e33acf9f325504": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "513c4a7409ed4ee3a2677db2426ae266": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55b864efb7d14a89bbb8c4eae39778ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ed6a20e243c47e690df62a9d997700b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fabc898b9ca4af1bb8d8cf94541e8b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61ad70c7507c401797d67967f01406bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "683df7bb7c574a039a9a6aaa4cdf6755": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fabc898b9ca4af1bb8d8cf94541e8b3",
            "placeholder": "​",
            "style": "IPY_MODEL_f1739aafd76c4a71b4ad93df9eec4aae",
            "value": "100%"
          }
        },
        "6f7fe965c9124e66999ab3edad54661e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8134cbf9ab024f63bbd03c2cf2fe3889": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_683df7bb7c574a039a9a6aaa4cdf6755",
              "IPY_MODEL_8b1a533b53204395903745f47f23707e",
              "IPY_MODEL_e0bfa4cecab64ba98f482d49b7798bfa"
            ],
            "layout": "IPY_MODEL_c747f75944194202b91dcc3900c458b8"
          }
        },
        "82ffbca1e4014a4db0d07ba0b47fc75b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b1a533b53204395903745f47f23707e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82ffbca1e4014a4db0d07ba0b47fc75b",
            "max": 1200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4e8679790d734063a0e33acf9f325504",
            "value": 1200
          }
        },
        "9017cef924294485be6119a2896c47f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55b864efb7d14a89bbb8c4eae39778ae",
            "placeholder": "​",
            "style": "IPY_MODEL_6f7fe965c9124e66999ab3edad54661e",
            "value": " 12000/12000 [00:05&lt;00:00, 2946.82it/s]"
          }
        },
        "9b8053fa904f41bbb1a18a0f3ce36ed6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e6bfd6d78564f06826763dfb9310eb9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9edcb83b5da141218282afa44d6ee035": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_027031949c084fd4b5046162c8a55693",
            "max": 12000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fa4affc1469043bf99deac511b2d981b",
            "value": 12000
          }
        },
        "acd6cd597bf146f2b6d7235677661d8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "baa87365978a44a3a2814f144d7c2f5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ed6a20e243c47e690df62a9d997700b",
            "placeholder": "​",
            "style": "IPY_MODEL_9b8053fa904f41bbb1a18a0f3ce36ed6",
            "value": "100%"
          }
        },
        "bbbe1e0f07e744508e7ece9ca2fb0cc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_513c4a7409ed4ee3a2677db2426ae266",
            "placeholder": "​",
            "style": "IPY_MODEL_61ad70c7507c401797d67967f01406bb",
            "value": "100%"
          }
        },
        "bd4f602f98a4467ba02aab3ab931f310": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5cdfdfabad84e5b83f0bd352692b04b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09258f93392b499ea4765a1eddbbd4b7",
            "max": 8580,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fd130db283644091b35dab14749e7e24",
            "value": 8580
          }
        },
        "c6beff3bae9a42f0bf273322113c7033": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bbbe1e0f07e744508e7ece9ca2fb0cc6",
              "IPY_MODEL_c5cdfdfabad84e5b83f0bd352692b04b",
              "IPY_MODEL_119aa0b1ff834630bddc3873cc5b003e"
            ],
            "layout": "IPY_MODEL_bd4f602f98a4467ba02aab3ab931f310"
          }
        },
        "c747f75944194202b91dcc3900c458b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0bfa4cecab64ba98f482d49b7798bfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c898aa72e6940dd8c64a9dfd3d86927",
            "placeholder": "​",
            "style": "IPY_MODEL_acd6cd597bf146f2b6d7235677661d8f",
            "value": " 1200/1200 [00:00&lt;00:00, 2335.69it/s]"
          }
        },
        "f1739aafd76c4a71b4ad93df9eec4aae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa4affc1469043bf99deac511b2d981b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd130db283644091b35dab14749e7e24": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
